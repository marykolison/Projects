{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom scipy.stats import ttest_ind\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-29T20:08:50.787396Z","iopub.execute_input":"2023-09-29T20:08:50.787773Z","iopub.status.idle":"2023-09-29T20:08:50.793285Z","shell.execute_reply.started":"2023-09-29T20:08:50.787746Z","shell.execute_reply":"2023-09-29T20:08:50.792491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:23:10.622160Z","iopub.execute_input":"2023-09-29T19:23:10.622889Z","iopub.status.idle":"2023-09-29T19:23:10.681761Z","shell.execute_reply.started":"2023-09-29T19:23:10.622858Z","shell.execute_reply":"2023-09-29T19:23:10.680516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:23:10.682851Z","iopub.execute_input":"2023-09-29T19:23:10.683129Z","iopub.status.idle":"2023-09-29T19:23:10.701386Z","shell.execute_reply.started":"2023-09-29T19:23:10.683106Z","shell.execute_reply":"2023-09-29T19:23:10.700118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.hist(figsize=(12, 8))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:23:10.702823Z","iopub.execute_input":"2023-09-29T19:23:10.703462Z","iopub.status.idle":"2023-09-29T19:23:11.365292Z","shell.execute_reply.started":"2023-09-29T19:23:10.703411Z","shell.execute_reply":"2023-09-29T19:23:11.364467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert 'TotalCharges' to numeric, coerce errors to NaN\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n\n# Ensure the 'Churn' column is categorical\ndf['Churn'] = df['Churn'].astype('category')\n\n# Create a box plot with 'Churn' as the x-axis and 'TotalCharges' as the y-axis\nsns.boxplot(x='Churn', y='TotalCharges', data=df)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:23:11.367350Z","iopub.execute_input":"2023-09-29T19:23:11.367838Z","iopub.status.idle":"2023-09-29T19:23:11.578213Z","shell.execute_reply.started":"2023-09-29T19:23:11.367808Z","shell.execute_reply":"2023-09-29T19:23:11.577060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='PaymentMethod', data=df)\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:23:11.580252Z","iopub.execute_input":"2023-09-29T19:23:11.580704Z","iopub.status.idle":"2023-09-29T19:23:11.792113Z","shell.execute_reply.started":"2023-09-29T19:23:11.580664Z","shell.execute_reply":"2023-09-29T19:23:11.791010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_columns = df.select_dtypes(include=['number'])\n\ncorr_matrix = numeric_columns.corr()\n\nplt.figure(figsize=(5, 5))\nsns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:23:11.793891Z","iopub.execute_input":"2023-09-29T19:23:11.794210Z","iopub.status.idle":"2023-09-29T19:23:12.079838Z","shell.execute_reply.started":"2023-09-29T19:23:11.794183Z","shell.execute_reply":"2023-09-29T19:23:12.078817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = numeric_columns\nfor col in cols:\n  print(f\"Value counts of {col} column\")\n  print(df[col].value_counts(), '\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:23:12.081387Z","iopub.execute_input":"2023-09-29T19:23:12.081917Z","iopub.status.idle":"2023-09-29T19:23:12.095135Z","shell.execute_reply.started":"2023-09-29T19:23:12.081889Z","shell.execute_reply":"2023-09-29T19:23:12.093757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert 'TotalCharges' to numeric, coerce errors to NaN\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n\n# Check for missing values\nmissing_values = df['TotalCharges'].isnull().sum()\nprint(f\"Number of missing values in 'TotalCharges': {missing_values}\")\n\n# Drop rows with missing 'TotalCharges' values or fill with a suitable value\n\n#perform the t-test\nchurned = df[df['Churn'] == 'Yes']['TotalCharges']\nnot_churned = df[df['Churn'] == 'No']['TotalCharges']\nt_statistic, p_value = ttest_ind(churned, not_churned)\nprint(f'T-statistic: {t_statistic}, p-value: {p_value}')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:23:12.096589Z","iopub.execute_input":"2023-09-29T19:23:12.097015Z","iopub.status.idle":"2023-09-29T19:23:12.113507Z","shell.execute_reply.started":"2023-09-29T19:23:12.096976Z","shell.execute_reply":"2023-09-29T19:23:12.112287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace missing values in 'MonthlyCharges' and 'TotalCharges' with the mean\nimputer = SimpleImputer(strategy='mean')\nX_imputed = df[['MonthlyCharges', 'TotalCharges']].copy()\nX_imputed[['MonthlyCharges', 'TotalCharges']] = imputer.fit_transform(X_imputed[['MonthlyCharges', 'TotalCharges']])\nkmeans = KMeans(n_clusters=3, n_init=4)  \ndf['Cluster'] = kmeans.fit_predict(X_imputed)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T20:06:10.299096Z","iopub.execute_input":"2023-09-29T20:06:10.299503Z","iopub.status.idle":"2023-09-29T20:06:10.730777Z","shell.execute_reply.started":"2023-09-29T20:06:10.299472Z","shell.execute_reply":"2023-09-29T20:06:10.729785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(['Churn'], axis=1)\ny = df['Churn']\n\n# Handle missing values in the dataset\n#SimpleImputer to fill missing numeric values with the mean\n# and missing categorical values with the most frequent value.\nnumeric_cols = X.select_dtypes(include='number').columns\ncategorical_cols = X.select_dtypes(exclude='number').columns\n\nnumeric_imputer = SimpleImputer(strategy='mean')\ncategorical_imputer = SimpleImputer(strategy='most_frequent')\n\nX[numeric_cols] = numeric_imputer.fit_transform(X[numeric_cols])\nX[categorical_cols] = categorical_imputer.fit_transform(X[categorical_cols])\n\nX_encoded = pd.get_dummies(X, drop_first=True)\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n\n# Build and evaluate a Random Forest classifier\nrf_classifier = RandomForestClassifier()\nrf_classifier.fit(X_train, y_train)\ny_pred = rf_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\nprint(classification_report(y_test, y_pred))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T20:05:48.110408Z","iopub.execute_input":"2023-09-29T20:05:48.110901Z","iopub.status.idle":"2023-09-29T20:06:03.090694Z","shell.execute_reply.started":"2023-09-29T20:05:48.110863Z","shell.execute_reply":"2023-09-29T20:06:03.089567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_encoded = pd.get_dummies(df, columns=['gender'], drop_first=True)\n\n# Apply one-hot encoding to the 'contract' column\ndf_encoded = pd.get_dummies(df_encoded, columns=['Churn'], drop_first=True)\n\n# Apply one-hot encoding to the 'payment method' column\ndf_encoded = pd.get_dummies(df_encoded, columns=['PaymentMethod'], drop_first=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T20:05:28.196886Z","iopub.execute_input":"2023-09-29T20:05:28.197309Z","iopub.status.idle":"2023-09-29T20:05:28.218409Z","shell.execute_reply.started":"2023-09-29T20:05:28.197276Z","shell.execute_reply":"2023-09-29T20:05:28.217583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"After encoding 'Churn':\")\nprint(df_encoded.head())\n\nprint(\"After encoding 'PaymentMethod':\")\nprint(df_encoded.head())","metadata":{"execution":{"iopub.status.busy":"2023-09-29T20:05:31.923215Z","iopub.execute_input":"2023-09-29T20:05:31.924104Z","iopub.status.idle":"2023-09-29T20:05:31.947765Z","shell.execute_reply.started":"2023-09-29T20:05:31.924068Z","shell.execute_reply":"2023-09-29T20:05:31.946753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the column names in your DataFrame\nprint(df.columns)\n\nnumerical_features = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n\n# Check the data types of columns\nprint(df.dtypes)\n\n# Ensure the specified column names exist in your DataFrame\nmissing_columns = [col for col in numerical_features if col not in df.columns]\nprint(\"Missing columns:\", missing_columns)\n\nprint(df.dtypes)\n\n# Ensure the specified column names exist in your DataFrame\nmissing_columns = [col for col in numerical_features if col not in df.columns]\nprint(\"Missing columns:\", missing_columns)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:34:03.586535Z","iopub.execute_input":"2023-09-29T19:34:03.587192Z","iopub.status.idle":"2023-09-29T19:34:03.596467Z","shell.execute_reply.started":"2023-09-29T19:34:03.587162Z","shell.execute_reply":"2023-09-29T19:34:03.595212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# Define the numerical features you want to use\nnumerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n\n# Define the target variable\ntarget_variable = 'Churn'\n\n# Impute missing values with the mean for numerical features\nimputer = SimpleImputer(strategy='mean')\nX_train[numerical_features] = imputer.fit_transform(X_train[numerical_features])\nX_test[numerical_features] = imputer.transform(X_test[numerical_features])\n\n# Initialize and train the Logistic Regression model\nmodel = LogisticRegression(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set and evaluate the model\n\ny_pred_proba = model.predict_proba(X_test)[:, 1] \n\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, pos_label='Yes')\nrecall = recall_score(y_test, y_pred, pos_label='Yes')\nf1 = f1_score(y_test, y_pred, pos_label='Yes')\nroc_auc = roc_auc_score(y_test, y_pred_proba)\n\n# Print the evaluation metrics\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)\nprint(f'ROC AUC Score: {roc_auc:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:58:37.516526Z","iopub.execute_input":"2023-09-29T19:58:37.516952Z","iopub.status.idle":"2023-09-29T19:58:37.788282Z","shell.execute_reply.started":"2023-09-29T19:58:37.516919Z","shell.execute_reply":"2023-09-29T19:58:37.786847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize and train the Random Forest model (you can replace RandomForestClassifier with your specific model)\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Get feature importances from the trained model\nfeature_importances = model.feature_importances_\n\nfeature_names = X_train.columns\n\n# Create a DataFrame to store the feature importances and their corresponding names\nfeature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n\n# Sort the features by importance in descending order\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n\n# Plot the top N most important features\ntop_n = 4\nplt.figure(figsize=(5, 6))\nplt.barh(range(top_n), feature_importance_df['Importance'][:top_n], align='center')\nplt.yticks(range(top_n), feature_importance_df['Feature'][:top_n])\nplt.xlabel('Feature Importance')\nplt.title(f'Top {top_n} Most Important Features')\nplt.gca().invert_yaxis() \nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T20:01:58.041431Z","iopub.execute_input":"2023-09-29T20:01:58.041783Z","iopub.status.idle":"2023-09-29T20:01:59.135623Z","shell.execute_reply.started":"2023-09-29T20:01:58.041757Z","shell.execute_reply":"2023-09-29T20:01:59.134544Z"},"trusted":true},"execution_count":null,"outputs":[]}]}